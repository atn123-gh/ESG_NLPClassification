{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1190f04",
   "metadata": {},
   "source": [
    "Reference :\n",
    "https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1427f2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.5.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.12.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.7/site-packages (0.5.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.14 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.0.17)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.8.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from accelerate) (1.7.1+cu110)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687ed839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #output 01\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# train = pd.read_csv('../../input/commonlitreadabilityprize/train.csv')\n",
    "# test = pd.read_csv('../../input/commonlitreadabilityprize/test.csv')\n",
    "\n",
    "# mlm_data = train[['excerpt']]\n",
    "# mlm_data = mlm_data.rename(columns={'excerpt':'text'})\n",
    "# mlm_data.to_csv('mlm_data.csv', index=False)\n",
    "\n",
    "# mlm_data_val = test[['excerpt']]\n",
    "# mlm_data_val = mlm_data_val.rename(columns={'excerpt':'text'})\n",
    "# mlm_data_val.to_csv('mlm_data_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_mlm_no_trainer.py \\\n",
    "#    \t--train_file 'mlm_data.csv' \\\n",
    "#    \t--validation_file  'mlm_data.csv' \\\n",
    "#    \t--validation_split_percentage 5 \\\n",
    "#    \t--pad_to_max_length  \\\n",
    "#    \t--model_name_or_path 'roberta-base' \\\n",
    "#    \t--config_name 'roberta-base' \\\n",
    "#    \t--tokenizer_name 'roberta-base' \\\n",
    "#    \t--use_slow_tokenizer  \\\n",
    "#    \t--per_device_train_batch_size 2 \\\n",
    "#    \t--per_device_eval_batch_size 2 \\\n",
    "#    \t--learning_rate 5e-5 \\\n",
    "#    \t--weight_decay 0.0 \\\n",
    "#    \t--num_train_epochs 1 \\\n",
    "#    \t--gradient_accumulation_steps 1 \\\n",
    "#    \t--num_warmup_steps 0 \\\n",
    "#    \t--output_dir 'pretrain620' \\\n",
    "#    \t--seed 2021 \\\n",
    "#    \t--model_type 'roberta' \\\n",
    "#    \t--line_by_line False \\\n",
    "#    \t--preprocessing_num_workers 4 \\\n",
    "#    \t--overwrite_cache  True\\\n",
    "#    \t--mlm_probability 0.15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fcd0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-15 04:18:23.348634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 339.69it/s]\n",
      " #0:   6%|██▍                                    | 1/16 [00:00<00:09,  1.64ba/s]\n",
      " #0:  19%|███████▎                               | 3/16 [00:01<00:06,  1.95ba/s]\u001b[A\n",
      " #1:   6%|██▍                                    | 1/16 [00:00<00:11,  1.35ba/s]\u001b[A\n",
      "\n",
      " #0:  25%|█████████▊                             | 4/16 [00:02<00:06,  1.82ba/s]\u001b[A\u001b[A\n",
      " #1:  12%|████▉                                  | 2/16 [00:01<00:09,  1.44ba/s]\u001b[A\n",
      "\n",
      " #0:  31%|████████████▏                          | 5/16 [00:02<00:05,  1.89ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3:   0%|                                               | 0/16 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #1:  19%|███████▎                               | 3/16 [00:01<00:08,  1.55ba/s]\u001b[A\n",
      "\n",
      " #0:  38%|██████████████▋                        | 6/16 [00:03<00:05,  1.91ba/s]\u001b[A\u001b[A\n",
      "\n",
      " #2:  19%|███████▎                               | 3/16 [00:01<00:06,  1.88ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3:   6%|██▍                                    | 1/16 [00:00<00:09,  1.54ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #0:  44%|█████████████████                      | 7/16 [00:03<00:04,  1.83ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  12%|████▉                                  | 2/16 [00:01<00:08,  1.75ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  25%|█████████▊                             | 4/16 [00:02<00:06,  1.79ba/s]\u001b[A\u001b[A\n",
      " #0:  50%|███████████████████▌                   | 8/16 [00:04<00:04,  1.85ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  19%|███████▎                               | 3/16 [00:01<00:06,  1.87ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  31%|████████████▏                          | 5/16 [00:02<00:05,  1.89ba/s]\u001b[A\u001b[A\n",
      " #0:  56%|█████████████████████▉                 | 9/16 [00:04<00:03,  1.91ba/s]\u001b[A\n",
      "\n",
      " #2:  38%|██████████████▋                        | 6/16 [00:03<00:05,  1.98ba/s]\u001b[A\u001b[A\n",
      " #1:  44%|█████████████████                      | 7/16 [00:04<00:04,  1.90ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #0:  62%|███████████████████████▊              | 10/16 [00:05<00:03,  1.98ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #1:  50%|███████████████████▌                   | 8/16 [00:04<00:03,  2.02ba/s]\u001b[A\n",
      "\n",
      " #2:  44%|█████████████████                      | 7/16 [00:03<00:04,  2.02ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #0:  69%|██████████████████████████▏           | 11/16 [00:05<00:02,  1.92ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  50%|███████████████████▌                   | 8/16 [00:04<00:03,  2.05ba/s]\u001b[A\u001b[A\n",
      " #0:  75%|████████████████████████████▌         | 12/16 [00:06<00:02,  1.97ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  38%|██████████████▋                        | 6/16 [00:03<00:05,  1.76ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  56%|█████████████████████▉                 | 9/16 [00:04<00:03,  2.11ba/s]\u001b[A\u001b[A\n",
      " #0:  81%|██████████████████████████████▉       | 13/16 [00:06<00:01,  2.03ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  44%|█████████████████                      | 7/16 [00:04<00:05,  1.73ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  62%|███████████████████████▊              | 10/16 [00:05<00:02,  2.11ba/s]\u001b[A\u001b[A\n",
      " #0:  88%|█████████████████████████████████▎    | 14/16 [00:07<00:00,  2.09ba/s]\u001b[A\n",
      "\n",
      " #2:  69%|██████████████████████████▏           | 11/16 [00:05<00:02,  2.10ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #0: 100%|██████████████████████████████████████| 16/16 [00:07<00:00,  2.07ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #1:  75%|████████████████████████████▌         | 12/16 [00:06<00:02,  1.78ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  56%|█████████████████████▉                 | 9/16 [00:05<00:03,  1.82ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  75%|████████████████████████████▌         | 12/16 [00:06<00:01,  2.03ba/s]\u001b[A\u001b[A\n",
      " #1:  81%|██████████████████████████████▉       | 13/16 [00:07<00:01,  1.79ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  62%|███████████████████████▊              | 10/16 [00:05<00:03,  1.95ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  81%|██████████████████████████████▉       | 13/16 [00:06<00:01,  2.07ba/s]\u001b[A\u001b[A\n",
      " #1:  88%|█████████████████████████████████▎    | 14/16 [00:07<00:01,  1.90ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  69%|██████████████████████████▏           | 11/16 [00:05<00:02,  1.96ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  88%|█████████████████████████████████▎    | 14/16 [00:07<00:00,  2.02ba/s]\u001b[A\u001b[A\n",
      " #1: 100%|██████████████████████████████████████| 16/16 [00:08<00:00,  1.94ba/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " #3:  75%|████████████████████████████▌         | 12/16 [00:06<00:01,  2.07ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2: 100%|██████████████████████████████████████| 16/16 [00:07<00:00,  2.11ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " #3:  81%|██████████████████████████████▉       | 13/16 [00:06<00:01,  2.07ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3:  88%|█████████████████████████████████▎    | 14/16 [00:07<00:00,  2.12ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3: 100%|██████████████████████████████████████| 16/16 [00:07<00:00,  2.06ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #0:   6%|██▍                                    | 1/16 [00:00<00:08,  1.67ba/s]\n",
      " #0:  12%|████▉                                  | 2/16 [00:01<00:07,  1.89ba/s]\u001b[A\n",
      " #0:  19%|███████▎                               | 3/16 [00:01<00:07,  1.69ba/s]\u001b[A\n",
      "\n",
      " #0:  25%|█████████▊                             | 4/16 [00:02<00:06,  1.80ba/s]\u001b[A\u001b[A\n",
      " #1:  12%|████▉                                  | 2/16 [00:01<00:10,  1.35ba/s]\u001b[A\n",
      "\n",
      " #0:  31%|████████████▏                          | 5/16 [00:02<00:05,  1.85ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3:   0%|                                               | 0/16 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #1:  19%|███████▎                               | 3/16 [00:02<00:09,  1.35ba/s]\u001b[A\n",
      "\n",
      " #0:  38%|██████████████▋                        | 6/16 [00:03<00:05,  1.89ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3:   6%|██▍                                    | 1/16 [00:00<00:09,  1.57ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  19%|███████▎                               | 3/16 [00:01<00:07,  1.71ba/s]\u001b[A\u001b[A\n",
      " #0:  44%|█████████████████                      | 7/16 [00:03<00:04,  1.80ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  12%|████▉                                  | 2/16 [00:01<00:08,  1.73ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  25%|█████████▊                             | 4/16 [00:02<00:06,  1.80ba/s]\u001b[A\u001b[A\n",
      " #0:  50%|███████████████████▌                   | 8/16 [00:04<00:04,  1.78ba/s]\u001b[A\n",
      "\n",
      " #2:  31%|████████████▏                          | 5/16 [00:02<00:05,  1.85ba/s]\u001b[A\u001b[A\n",
      " #1:  38%|██████████████▋                        | 6/16 [00:03<00:05,  1.74ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #0:  56%|█████████████████████▉                 | 9/16 [00:04<00:03,  1.82ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  38%|██████████████▋                        | 6/16 [00:03<00:05,  1.95ba/s]\u001b[A\u001b[A\n",
      " #1:  44%|█████████████████                      | 7/16 [00:04<00:04,  1.87ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #0:  62%|███████████████████████▊              | 10/16 [00:05<00:03,  1.93ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #1:  50%|███████████████████▌                   | 8/16 [00:04<00:03,  2.01ba/s]\u001b[A\n",
      "\n",
      " #2:  44%|█████████████████                      | 7/16 [00:03<00:04,  2.01ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #0:  69%|██████████████████████████▏           | 11/16 [00:05<00:02,  1.89ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #1:  56%|█████████████████████▉                 | 9/16 [00:05<00:03,  2.01ba/s]\u001b[A\n",
      "\n",
      " #2:  50%|███████████████████▌                   | 8/16 [00:04<00:03,  2.03ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #0:  75%|████████████████████████████▌         | 12/16 [00:06<00:02,  1.99ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  56%|█████████████████████▉                 | 9/16 [00:04<00:03,  2.13ba/s]\u001b[A\u001b[A\n",
      " #1:  62%|███████████████████████▊              | 10/16 [00:05<00:03,  2.00ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #0:  81%|██████████████████████████████▉       | 13/16 [00:06<00:01,  2.09ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  62%|███████████████████████▊              | 10/16 [00:05<00:02,  2.20ba/s]\u001b[A\u001b[A\n",
      " #0:  88%|█████████████████████████████████▎    | 14/16 [00:07<00:00,  2.21ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  50%|███████████████████▌                   | 8/16 [00:04<00:04,  1.91ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  69%|██████████████████████████▏           | 11/16 [00:05<00:02,  2.20ba/s]\u001b[A\u001b[A\n",
      " #0:  94%|███████████████████████████████████▋  | 15/16 [00:07<00:00,  2.16ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #0: 100%|██████████████████████████████████████| 16/16 [00:07<00:00,  2.06ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #2:  75%|████████████████████████████▌         | 12/16 [00:05<00:01,  2.17ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3:  62%|███████████████████████▊              | 10/16 [00:05<00:02,  2.10ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #1:  81%|██████████████████████████████▉       | 13/16 [00:07<00:01,  1.85ba/s]\u001b[A\n",
      "\n",
      " #2:  81%|██████████████████████████████▉       | 13/16 [00:06<00:01,  2.21ba/s]\u001b[A\u001b[A\n",
      " #1:  88%|█████████████████████████████████▎    | 14/16 [00:07<00:01,  1.96ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #3:  69%|██████████████████████████▏           | 11/16 [00:05<00:02,  2.05ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2:  88%|█████████████████████████████████▎    | 14/16 [00:06<00:00,  2.16ba/s]\u001b[A\u001b[A\n",
      " #1: 100%|██████████████████████████████████████| 16/16 [00:08<00:00,  1.95ba/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " #3:  75%|████████████████████████████▌         | 12/16 [00:06<00:01,  2.14ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2: 100%|██████████████████████████████████████| 16/16 [00:07<00:00,  2.15ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " #3:  81%|██████████████████████████████▉       | 13/16 [00:06<00:01,  2.16ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3:  88%|█████████████████████████████████▎    | 14/16 [00:07<00:00,  2.18ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #3: 100%|██████████████████████████████████████| 16/16 [00:07<00:00,  2.12ba/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████| 30254/30254 [3:07:21<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "!python run_mlm_no_trainer.py \\\n",
    "   \t--train_file 'allEgText.csv' \\\n",
    "   \t--validation_file  'allEgText_test.csv' \\\n",
    "   \t--validation_split_percentage 5 \\\n",
    "   \t--pad_to_max_length  \\\n",
    "   \t--model_name_or_path 'roberta-base' \\\n",
    "   \t--config_name 'roberta-base' \\\n",
    "   \t--tokenizer_name 'roberta-base' \\\n",
    "   \t--use_slow_tokenizer  \\\n",
    "   \t--per_device_train_batch_size 2 \\\n",
    "   \t--per_device_eval_batch_size 2 \\\n",
    "   \t--learning_rate 5e-5 \\\n",
    "   \t--weight_decay 0.0 \\\n",
    "   \t--num_train_epochs 1 \\\n",
    "   \t--gradient_accumulation_steps 1 \\\n",
    "   \t--num_warmup_steps 30 \\\n",
    "   \t--output_dir 'pretrain620' \\\n",
    "   \t--seed 221 \\\n",
    "   \t--model_type 'roberta' \\\n",
    "   \t--line_by_line True \\\n",
    "   \t--preprocessing_num_workers 4 \\\n",
    "   \t--overwrite_cache  False\\\n",
    "   \t--mlm_probability 0.15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c5a809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (2834, 6)\n"
     ]
    }
   ],
   "source": [
    "# #output_noTest2\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# train = pd.read_csv('../../input/commonlitreadabilityprize/train.csv')\n",
    "# test = pd.read_csv('../../input/commonlitreadabilityprize/test.csv')\n",
    "# train=train.sort_values(by='target').reset_index(drop=True)\n",
    "# print(\"train\",train.shape)\n",
    "\n",
    "# #split train and test\n",
    "# test2=train.iloc[::30, :]\n",
    "# train=train.drop(test2.index,axis=0)\n",
    "\n",
    "# test2=test2.reset_index(drop=True)\n",
    "# train=train.reset_index(drop=True)\n",
    "# mlm_data = train[['excerpt']]\n",
    "# mlm_data = mlm_data.rename(columns={'excerpt':'text'})\n",
    "# # mlm_data.to_csv('mlm_data_noTest2.csv', index=False)\n",
    "\n",
    "# mlm_data_val = test[['excerpt']]\n",
    "# mlm_data_val = mlm_data_val.rename(columns={'excerpt':'text'})\n",
    "# # mlm_data_val.to_csv('mlm_data_val_noTest2.csv', index=False)\n",
    "\n",
    "# mlm_data_test = test2[['excerpt']]\n",
    "# mlm_data_test = mlm_data_test.rename(columns={'excerpt':'text'})\n",
    "# mlm_data_test.to_csv('mlm_data_test_noTest2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808a14d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-04 01:59:39.922609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\n",
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-70816dad3a4bdc63/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n",
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-70816dad3a4bdc63/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n",
      " #0:   0%|                                                | 0/1 [00:00<?, ?ba/s]\n",
      " #0: 100%|████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/ba]\u001b[A\n",
      "\n",
      "\n",
      " #2:   0%|                                                | 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
      " #1: 100%|████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/ba]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " #3:   0%|                                                | 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " #2: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  1.10ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " #3: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  1.25ba/s]\u001b[A\u001b[A\u001b[A\n",
      " #0: 100%|███████████████████████████████████████| 1/1 [00:00<00:00, 147.09ba/s]\n",
      "\n",
      " #1: 100%|███████████████████████████████████████| 1/1 [00:00<00:00, 117.53ba/s]\u001b[A\n",
      "\n",
      "\n",
      " #2: 100%|███████████████████████████████████████| 1/1 [00:00<00:00, 126.56ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " #3: 100%|███████████████████████████████████████| 1/1 [00:00<00:00, 230.96ba/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████| 1370/1370 [06:34<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# !python run_mlm_no_trainer.py \\\n",
    "#    \t--train_file 'mlm_data_noTest2.csv' \\\n",
    "#    \t--validation_file  'mlm_data_val_noTest2.csv' \\\n",
    "#    \t--validation_split_percentage 5 \\\n",
    "#    \t--pad_to_max_length  \\\n",
    "#    \t--model_name_or_path 'roberta-base' \\\n",
    "#    \t--config_name 'roberta-base' \\\n",
    "#    \t--tokenizer_name 'roberta-base' \\\n",
    "#    \t--use_slow_tokenizer  \\\n",
    "#    \t--per_device_train_batch_size 2 \\\n",
    "#    \t--per_device_eval_batch_size 2 \\\n",
    "#    \t--learning_rate 5e-5 \\\n",
    "#    \t--weight_decay 0.0 \\\n",
    "#    \t--num_train_epochs 1 \\\n",
    "#    \t--gradient_accumulation_steps 1 \\\n",
    "#    \t--num_warmup_steps 0 \\\n",
    "#    \t--output_dir 'output_noTest2' \\\n",
    "#    \t--seed 2021 \\\n",
    "#    \t--model_type 'roberta' \\\n",
    "#    \t--line_by_line False \\\n",
    "#    \t--preprocessing_num_workers 4 \\\n",
    "#    \t--overwrite_cache  True\\\n",
    "#    \t--mlm_probability 0.15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f6667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"run_glue.py\", line 27, in <module>\n",
      "    from datasets import load_dataset, load_metric\n",
      "ModuleNotFoundError: No module named 'datasets'\n"
     ]
    }
   ],
   "source": [
    "# !python run_glue.py \\\n",
    "# \t--max_seq_length  250 \\\n",
    "# \t--train_file 'mlm_data.csv'\\\n",
    "# \t--validation_file 'mlm_data_val_noTest2.csv' \\\n",
    "# \t--test_file 'mlm_data_test_noTest2.csv'\\\n",
    "# \t--model_name_or_path 'roberta-base'\\\n",
    "# \t--tokenizer_name 'roberta-base' \\\n",
    "# \t--config_name 'output_noTest2/'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
